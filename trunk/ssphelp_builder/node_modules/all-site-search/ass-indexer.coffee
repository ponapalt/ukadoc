fs = require 'fs'
path = require 'path'
cheerio = require 'cheerio'
argv = require 'argv'
AllSiteSearch = require './all-site-search'

argv.option [
	{
		name: 'output'
		short: 'o'
		type: 'path'
		description: '作成するデータベースファイル(デフォルトは"assdb.json")'
	}
	{
		name: 'ignore_files'
		short: 'i'
		type: 'csv,string'
		description: '無視するファイル(カンマ区切り)'
		example: '-i "search.html,contents.html"'
	}
	{
		name: 'use_fake_id'
		short: 'f'
		type: 'boolean'
		description: 'idのないヘッダにも擬似的にidをふる'
	}
]

argv.info '''
	Usage: ass-indexer [options] directory(single)
	
	指定ディレクトリの全文検索インデックスとスニペットリストを作成する。
	標準ではページ全体とidをもつヘッディング(h1, h2...)に続く各領域が1範囲となる。
'''

{targets, options} = argv.run()

unless targets.length == 1
	argv.help()
	process.exit 0
dir = targets[0]
files = fs.readdirSync dir

for file in files
	if file.match(/\.html$/) and (!options.ignore_files? or options.ignore_files.indexOf(file) == -1)
		filepath = path.join dir, file
		console.log 'read: ', filepath
		html = fs.readFileSync filepath
		AllSiteSearch.add_html file, html, '#contents', options.use_fake_id

db = AllSiteSearch.serialize()

output = if options.output? then options.output else 'assdb.json'
fs.writeFileSync output, JSON.stringify(db)
